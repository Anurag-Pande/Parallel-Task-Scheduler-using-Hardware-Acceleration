{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TENSORFLOW INSTALLATION**"
      ],
      "metadata": {
        "id": "BlH00DyWwfbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y29HWCZCQpkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a240cec-309c-49d3-ce5f-443b05065095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (68.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (68.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (68.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.41.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: nvidia-pyindex in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cudnn\n",
            "  Using cached nvidia-cudnn-0.0.1.dev5.tar.gz (7.9 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install --root-user-action=ignore\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install tensorflow-gpu\n",
        "!pip install --upgrade setuptools wheel\n",
        "!pip install --upgrade pip\n",
        "!pip install nvidia-pyindex\n",
        "!pip install nvidia-cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TENSORFLOW UPGRADE**"
      ],
      "metadata": {
        "id": "R-pPjVnc0X7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get install -y libcudnn7=7.6.5.32-1+cuda10.0 libcudnn7-dev=7.6.5.32-1+cuda10.0\n",
        "# !apt-get install -y libnccl2=2.4.8-1+cuda10.0 libnccl-dev=2.4.8-1+cuda10.0"
      ],
      "metadata": {
        "id": "wDSwEGkoRBnu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Qq77JfbSwhy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCJJUNORKzuS",
        "outputId": "a62fc88f-f367-4c60-d777-f6a8ce6fcc27"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 4480393739698743960\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14410383360\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 10058110403534530961\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsryuHj7LhN0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1X8hWcjLuJh",
        "outputId": "0c26feeb-f888-4b6e-bf03-be354a1796a7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 17 14:45:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    30W /  70W |    565MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(physical_devices)"
      ],
      "metadata": {
        "id": "Zf7GSzk3L1J-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8a41d4-05c5-4161-e8a8-f126ac2424d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO CHECK THE GPU AVAILABILITY**"
      ],
      "metadata": {
        "id": "EqFYxqaR0eRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if not physical_devices:\n",
        "    raise SystemError('No GPU detected')\n",
        "else:\n",
        "    print('GPU is available')\n",
        "\n",
        "# Print the GPU device name and version\n"
      ],
      "metadata": {
        "id": "9-XqsvamQ7CU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9e893c-0b70-41a7-f01b-c68d9905982a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.test.gpu_device_name())"
      ],
      "metadata": {
        "id": "lmXPZm_OMEkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153740c0-bae6-40ac-a023-910371430a63"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"GPU is available\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL1k0WGKrfEL",
        "outputId": "9bb3a1d6-4b6a-4758-cc43-d6b34244de83"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO CHECK THE MULTIPROCESSING OF LIST OF TASKS**"
      ],
      "metadata": {
        "id": "QmU8xkRJ0szF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    raise SystemError('No GPU detected')\n",
        "\n",
        "# Define a parallel task\n",
        "@tf.function\n",
        "def parallel_task(x):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        # Define your GPU-accelerated computation here\n",
        "        return x * x\n",
        "\n",
        "# Define the list of tasks\n",
        "tasks = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Use the GPU-accelerated task on each element of the list\n",
        "results = [parallel_task(tf.constant(task)).numpy() for task in tasks]\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "fJ6a_bl3Rjmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc321241-c729-4b2c-b031-ac284cf1aabe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO EXECUTE THE TASKS IN SEQUENTIAL AND PARALLEL WITH EXECUTION TIME**"
      ],
      "metadata": {
        "id": "DC4U4iwI0wbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import time\n",
        "\n",
        "# Define a task function to be executed in parallel\n",
        "def parallel_task(x):\n",
        "    # Replace this with your actual task logic\n",
        "    result = x * x\n",
        "    return result\n",
        "\n",
        "# Number of tasks to execute in parallel\n",
        "num_tasks = 5\n",
        "tasks = [1, 2, 3, 4, 5]  # Example tasks, you can use different numbers\n",
        "\n",
        "# Measure the runtime for sequential execution\n",
        "start_time = time.time()\n",
        "sequential_results = [parallel_task(x) for x in tasks]\n",
        "sequential_runtime = time.time() - start_time\n",
        "\n",
        "# Create a ThreadPoolExecutor for parallel execution\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Measure the runtime for parallel execution\n",
        "    start_time = time.time()\n",
        "    parallel_results = list(executor.map(parallel_task, tasks))\n",
        "    parallel_runtime = time.time() - start_time\n",
        "\n",
        "print(\"Sequential Results:\", sequential_results)\n",
        "print(\"Sequential Runtime:\", sequential_runtime, \"seconds\")\n",
        "\n",
        "print(\"Parallel Results:\", parallel_results)\n",
        "print(\"Parallel Runtime:\", parallel_runtime, \"seconds\")"
      ],
      "metadata": {
        "id": "fZwpuLodSQiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b23889f-0183-49f1-8d25-755b466ca804"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential Results: [1, 4, 9, 16, 25]\n",
            "Sequential Runtime: 0.00014829635620117188 seconds\n",
            "Parallel Results: [1, 4, 9, 16, 25]\n",
            "Parallel Runtime: 0.0006117820739746094 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO EXECUTE THE TASKS IN SEQUENTIAL AND PARALLEL OF MATRIX MULTIPLICATION WITH EXECUTION TIME**"
      ],
      "metadata": {
        "id": "NwJcCiwT0886"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def matrix_multiply(a, b):\n",
        "    return np.dot(a, b)\n",
        "def sequential_matrix_multiplication(a, b):\n",
        "    start_time = time.time()\n",
        "    result = matrix_multiply(a, b)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return result, execution_time\n",
        "def parallel_matrix_multiplication(a, b, num_workers):\n",
        "    start_time = time.time()\n",
        "    chunk_size = len(a) // num_workers\n",
        "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "        chunks = [(a[i:i+chunk_size], b) for i in range(0, len(a), chunk_size)]\n",
        "        results = list(executor.map(matrix_multiply, *zip(*chunks)))\n",
        "    result = np.concatenate(results)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return result, execution_time\n",
        "\n",
        "# Example usage\n",
        "matrix_size = 1000\n",
        "matrix_a = np.random.rand(matrix_size, matrix_size)\n",
        "matrix_b = np.random.rand(matrix_size, matrix_size)\n",
        "\n",
        "# Sequential execution\n",
        "sequential_result, sequential_time = sequential_matrix_multiplication(matrix_a, matrix_b)\n",
        "print(f\"Sequential Execution Time: {sequential_time} seconds\")\n",
        "\n",
        "# Parallel execution with 4 workers\n",
        "num_workers = 4\n",
        "parallel_result, parallel_time = parallel_matrix_multiplication(matrix_a, matrix_b, num_workers)\n",
        "print(f\"Parallel Execution Time with {num_workers} workers: {parallel_time} seconds\")\n",
        "\n",
        "# Ensure the results are the same for sequential and parallel execution\n",
        "assert np.allclose(sequential_result, parallel_result), \"Results do not match!\""
      ],
      "metadata": {
        "id": "HARBsGmOTT6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09967f68-a9a4-4c6c-bc7c-302e2c26b226"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential Execution Time: 0.06389808654785156 seconds\n",
            "Parallel Execution Time with 4 workers: 0.5282261371612549 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO EXECUTE THE TASKS IN SEQUENTIAL AND PARALLEL OF MATRIX MULTIPLICATION WITH EXECUTION TIME USING GPU ACCELERATION**"
      ],
      "metadata": {
        "id": "BI9t3nMu1Ojj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    raise SystemError('No GPU detected')\n",
        "\n",
        "# Define a GPU-accelerated complex task (matrix multiplication)\n",
        "def gpu_complex_task(size):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        # Generate random matrices and perform matrix multiplication\n",
        "        mat1 = tf.constant(np.random.rand(size, size), dtype=tf.float32)\n",
        "        mat2 = tf.constant(np.random.rand(size, size), dtype=tf.float32)\n",
        "        result = tf.matmul(mat1, mat2)\n",
        "        return result.numpy()\n",
        "\n",
        "# Number of tasks to execute in parallel\n",
        "num_tasks = 5\n",
        "task_sizes = [500, 750, 1000, 1250, 1500]  # Example task sizes, you can use different sizes\n",
        "\n",
        "# Measure the runtime for sequential execution\n",
        "start_time = time.time()\n",
        "sequential_results = [gpu_complex_task(size) for size in task_sizes]\n",
        "sequential_runtime = time.time() - start_time\n",
        "\n",
        "# Create a ThreadPoolExecutor for parallel execution\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Measure the runtime for parallel execution\n",
        "    start_time = time.time()\n",
        "    parallel_results = list(executor.map(gpu_complex_task, task_sizes))\n",
        "    parallel_runtime = time.time() - start_time\n",
        "\n",
        "print(\"Sequential Results:\", [result.shape for result in sequential_results])\n",
        "print(\"Sequential Runtime:\", sequential_runtime, \"seconds\")\n",
        "\n",
        "print(\"Parallel Results:\", [result.shape for result in parallel_results])\n",
        "print(\"Parallel Runtime:\", parallel_runtime, \"seconds\")"
      ],
      "metadata": {
        "id": "iFlHffSZSqDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a6380a-fc3e-4d4d-8175-8a422a9b2c40"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "Sequential Results: [(500, 500), (750, 750), (1000, 1000), (1250, 1250), (1500, 1500)]\n",
            "Sequential Runtime: 0.18117046356201172 seconds\n",
            "Parallel Results: [(500, 500), (750, 750), (1000, 1000), (1250, 1250), (1500, 1500)]\n",
            "Parallel Runtime: 0.17812228202819824 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Count Program"
      ],
      "metadata": {
        "id": "klmN1Oc1F9Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_word_count(text):\n",
        "    word_count = 0\n",
        "    in_word = False\n",
        "\n",
        "    for char in text:\n",
        "        if char.isalnum():\n",
        "            in_word = True\n",
        "        else:\n",
        "            if in_word:\n",
        "                word_count += 1\n",
        "                in_word = False\n",
        "\n",
        "    if in_word:\n",
        "        word_count += 1\n",
        "\n",
        "    return word_count"
      ],
      "metadata": {
        "id": "fgLSLkoNE1FC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_word_count(text, num_processes=2):\n",
        "  chunk_size = len(text) // num_processes\n",
        "  chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "  with concurrent.futures.ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
        "    # Measure the time before running the parallel word count\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Submit the count_words function for each chunk\n",
        "    futures = [executor.submit(sequential_word_count, chunk) for chunk in chunks]\n",
        "\n",
        "    # Wait for all tasks to complete\n",
        "    concurrent.futures.wait(futures)\n",
        "\n",
        "    # Get the results from completed tasks and sum them\n",
        "    result = sum(future.result() for future in futures)\n",
        "\n",
        "    # Measure the time after running the parallel word count\n",
        "    end_time = time.time()\n",
        "\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  return result, elapsed_time\n"
      ],
      "metadata": {
        "id": "0t5CVuvOGH5O"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_text = \"This is a simple example for word count with parallel processing.\"\n",
        "input_path = '/content/Word_Count.txt'\n",
        "with open(input_path, 'r') as file:\n",
        "  input_text = file.read()\n",
        "#sequential_result, sequential_time = sequential_word_count(input_text)\n",
        "parallel_result, parallel_time = parallel_word_count(input_text)\n",
        "\n",
        "start_time = time.time()\n",
        "result = sequential_word_count(input_text)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Sequential Word count: {result}\")\n",
        "print(f\"Sequential Time taken: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "num_threads = 16\n",
        "\n",
        "result, elapsed_time = parallel_word_count(input_text, num_threads)\n",
        "print(f\"Parallel Word count: {result}\")\n",
        "print(f\"Parallel Time taken: {elapsed_time:.6f} seconds with {num_threads} threads\")"
      ],
      "metadata": {
        "id": "v8fSZ1nAGLe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc3c0b1-aebc-4b6e-a4d4-514b6b220d31"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential Word count: 12500\n",
            "Sequential Time taken: 0.006938 seconds\n",
            "Parallel Word count: 12513\n",
            "Parallel Time taken: 0.436659 seconds with 16 threads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJWRUXr_GmuP"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}